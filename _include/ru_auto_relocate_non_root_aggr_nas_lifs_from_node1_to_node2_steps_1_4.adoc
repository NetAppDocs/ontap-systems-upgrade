NOTE: The home owner for the aggregates and LIFs are not modified; only the current -owner is modified.

.Steps

. Resume the aggregate relocation and NAS data LIF move operations:
+
`system controller replace resume`
+
All the non-root aggregates and NAS data LIFs are migrated from node1 to node2.
+
The operation pauses to allow you to verify whether all node1 non-root aggregates and non-SAN data LIFs have been migrated to node2.

. Check the status of the aggregate relocation and NAS data LIF move operations:
+
`system controller replace show-details`

. With the operation still paused, verify that all the non-root aggregates are online for their state on node2:
+
`storage aggregate show -node <node2> -state online -root false`
+
The following example shows that the non-root aggregates on node2 are online:
+
----
cluster::> storage aggregate show -node node2 state online -root false

Aggregate  Size     Available  Used%  State  #Vols  Nodes  RAID Status
---------  -------  ---------  -----  ------ -----  ------ --------------
aggr_1     744.9GB  744.8GB    0%     online     5  node2  raid_dp,normal
aggr_2     825.0GB  825.0GB    0%     online     1  node2  raid_dp,normal
2 entries were displayed.
----
+
If the aggregates have gone offline or become foreign on node2, bring them online by using the following command on node2, once for each aggregate:
+
`storage aggregate online -aggregate <aggr_name>`

. Verify that all the volumes are online on node2 by using the following command on node2 and examining its output:
+
`volume show -node <node2> -state offline`
+
If any volumes are offline on node2, bring them online by using the following command on node2, once for each volume:
+
`volume online -vserver <vserver-name> -volume <volume-name>`
+
The `<vserver-name>` to use with this command is found in the output of the previous `volume show` command.
